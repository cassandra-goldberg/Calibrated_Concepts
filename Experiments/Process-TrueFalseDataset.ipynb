{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3806345-3c6b-41bf-9f74-4b551b29c7d5",
   "metadata": {},
   "source": [
    "# Process True False Dataset\n",
    "\n",
    "Dataset from the paper [The Internal State of an LLM Knows When It's Lying](https://aclanthology.org/2023.findings-emnlp.68.pdf)\n",
    "\n",
    "You can download the dataset [here](http://azariaa.com/Content/Datasets/true-false-dataset.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f6c14-d2bf-4573-8048-a08df2634e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from utils import add_split_column\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"CPU\"\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec63df3-9723-46a3-bada-4bf7e38e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'true-false-dataset'\n",
    "categories = ['animals', 'cities', 'companies', 'elements', \n",
    "              'facts', 'generated', 'inventions']\n",
    "only_train = True\n",
    "\n",
    "data_path = f'../Data/{dataset_name}'\n",
    "embeddings_path = f'Embeddings/{dataset_name}'\n",
    "concepts_path = f'Concepts/{dataset_name}'\n",
    "cos_sims_path = f'Cosine_Similarities/{dataset_name}'\n",
    "images_path = f'Images/{dataset_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240aa09-dc31-45f6-859e-f3e5b77d3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file = os.path.join(embeddings_path, 'embeddings.pt')\n",
    "    \n",
    "if os.path.exists(embeddings_file):\n",
    "    print('Embeddings file found. No need to load model and tokenizer.')\n",
    "    model = None\n",
    "    tokenizer = None\n",
    "else:\n",
    "    print('Embeddings file NOT found. Loading model and tokenizer...')\n",
    "    \n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()\n",
    "    \n",
    "    model_name_or_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a956e43-ba35-4ae6-b4a8-43b6472dd9d9",
   "metadata": {},
   "source": [
    "## Processing statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588f998-dc4b-4aba-9b00-4bc23ef91f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(category, data_path):\n",
    "    cat_path = os.path.join(data_path, f'{category}_true_false.csv')\n",
    "    df_cat = pd.read_csv(cat_path)\n",
    "    df_cat[category] = 1\n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520ed8c-f445-4df4-b4e4-95e69754fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(categories, data_path):\n",
    "    df_list = []\n",
    "    for category in categories:\n",
    "        df_cat = get_category(category, data_path=data_path)\n",
    "        df_list.append(df_cat)\n",
    "    metadata_df = pd.concat(df_list, ignore_index=True)\n",
    "    metadata_df = metadata_df.fillna(0)\n",
    "    for category in categories:\n",
    "        metadata_df[category] = metadata_df[category].astype(int)\n",
    "    metadata_df = metadata_df.rename(columns={'label': 'true'})\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1df244-4b20-422c-ab53-1aab03a2eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(statements, model, tokenizer, embeddings_path, \n",
    "                      device=device, save=True):\n",
    "    embeddings_file = os.path.join(embeddings_path, 'embeddings.pt')\n",
    "    \n",
    "    if os.path.exists(embeddings_file):\n",
    "        print('   Hidden states file found.')\n",
    "        hidden_states = torch.load(embeddings_file)\n",
    "    else:\n",
    "        print('   Hidden states file NOT found.')\n",
    "        hidden_states = []\n",
    "        for statement in tqdm(statements, desc='Getting hidden states'):\n",
    "            tokenized_prompt = tokenizer(statement, return_tensors=\"pt\").to(device)\n",
    "            output = model(**tokenized_prompt, output_hidden_states=True)\n",
    "            \n",
    "            features = output.hidden_states[-1][0][-1]\n",
    "            hidden_state = features.cpu().detach()\n",
    "            hidden_states.append(hidden_state)\n",
    "            \n",
    "            del output\n",
    "            del features\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        hidden_states = torch.stack(hidden_states, dim=0)\n",
    "        # Center embeddings\n",
    "        average_embedding = torch.mean(hidden_states, 0) \n",
    "        centered_hidden_states = hidden_states - average_embedding\n",
    "        if save:\n",
    "            os.makedirs(embeddings_path, exist_ok=True)\n",
    "            torch.save(hidden_states, embeddings_file)\n",
    "            \n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9b7fa-5c40-4131-9de7-c9e9a976f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(categories, model, tokenizer, data_path, embeddings_path):\n",
    "    print('Getting statements...', end=' ')\n",
    "    metadata_df = get_categories(categories, data_path=data_path)\n",
    "    metadata_df = add_split_column(metadata_df)\n",
    "    metadata_df.to_csv(os.path.join(data_path, 'metadata.csv'), index=False)\n",
    "    \n",
    "    statements = metadata_df['statement'].to_list()\n",
    "\n",
    "    train_mask = metadata_df['split'] == 'train'\n",
    "    train_metadata_df = metadata_df[train_mask].reset_index(drop=True)\n",
    "    train_metadata_df.to_csv(os.path.join(data_path, 'train_metadata.csv'), index=False)\n",
    "    print('Done.')\n",
    "\n",
    "    print('Getting hidden states...')\n",
    "    hidden_states = get_hidden_states(statements, model, tokenizer, embeddings_path)\n",
    "    train_hidden_states = hidden_states[train_mask]\n",
    "    torch.save(train_hidden_states, os.path.join(embeddings_path, 'train_embeddings.pt'))\n",
    "    print('Done.')\n",
    "\n",
    "    return metadata_df, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12de0a-0af1-4350-a057-2304b62c7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df, hidden_states = process_data(categories, model, tokenizer, data_path, embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad90a36-3bfe-479e-951f-932726f3a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of statements: {metadata_df.shape[0]}')\n",
    "print(f'Number of true statements: {metadata_df[metadata_df[\"true\"] == 1].shape[0]}')\n",
    "print(f'Number of false statements: {metadata_df[metadata_df[\"true\"] == 0].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c039b2d-be13-4cf9-8b03-5674895f3771",
   "metadata": {},
   "source": [
    "## Computing concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb60d4c-9cf4-47c7-a157-aff00c43a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_concept(concept, metadata_df, hidden_states):\n",
    "    # Get embeddings from the concept\n",
    "    hidden_states_cat = hidden_states[metadata_df[concept]==1] \n",
    "    # Get average embedding\n",
    "    concept_vect = torch.mean(hidden_states_cat, 0) \n",
    "    # Normalize vector\n",
    "    concept_vect = concept_vect / concept_vect.norm() \n",
    "    return concept_vect\n",
    "\n",
    "def compute_concepts(metadata_df, hidden_states, concepts_path, save=True, only_train=True):\n",
    "    if only_train:\n",
    "        train_mask = metadata_df['split'] == 'train'\n",
    "        hidden_states = hidden_states[train_mask]\n",
    "        metadata_df = metadata_df[train_mask].reset_index(drop=True)\n",
    "    concept_names = list(metadata_df.columns[1:-1])\n",
    "    concepts = {}\n",
    "\n",
    "    print('Computing concept vectors...', end=' ')\n",
    "    for concept in concept_names:\n",
    "        concept_vect = compute_single_concept(concept, metadata_df, hidden_states)\n",
    "        concepts[concept] = concept_vect\n",
    "    print('Done.')\n",
    "        \n",
    "    if save:\n",
    "        print('Saving concepts...', end=' ')\n",
    "        os.makedirs(concepts_path, exist_ok=True)\n",
    "        if only_train:\n",
    "            concepts_path = os.path.join(concepts_path, 'train_concepts.pt')\n",
    "        else:\n",
    "            concepts_path = os.path.join(concepts_path, 'concepts.pt')\n",
    "        torch.save(concepts, concepts_path)\n",
    "        print('Done.')\n",
    "\n",
    "    print(f'Concepts computed: {list(concepts.keys())}')\n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fdb6f-1f86-4a3f-96c2-2b653c254645",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = compute_concepts(metadata_df, hidden_states, concepts_path, only_train=only_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39210c-4073-44cf-bc7d-5b239cb1c640",
   "metadata": {},
   "source": [
    "## Compute cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6c2cb-860c-4ffd-a316-00049b43d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_sims(hidden_states, metadata_df, concept_embs, concept_names, cos_sims_path,\n",
    "                        save=True, only_train=True):\n",
    "    print('Computing cosine similarities...', end=' ')\n",
    "    similarities = cosine_similarity(hidden_states, concept_embs)\n",
    "    cosine_similarity_df = pd.DataFrame(similarities, columns=concept_names)\n",
    "    print('Done.')\n",
    "    if save:\n",
    "        print('Saving cosine similarities...', end=' ')\n",
    "        os.makedirs(cos_sims_path, exist_ok=True)\n",
    "        if only_train:\n",
    "            cos_sims_df_path = os.path.join(cos_sims_path, 'train_cosine_similarities.csv')\n",
    "        else:\n",
    "            cos_sims_df_path = os.path.join(cos_sims_path, 'cosine_similarities.csv')\n",
    "        cosine_similarity_df.to_csv(cos_sims_df_path, index=False)\n",
    "        print('Done.')\n",
    "        \n",
    "    return cosine_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c89b6-10f0-42f6-b228-c2b3eb7b6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embs = torch.stack(list(concepts.values()), dim=0)\n",
    "concept_names = list(concepts.keys())\n",
    "cosine_similarity_df = compute_cosine_sims(hidden_states, metadata_df, concept_embs, concept_names, cos_sims_path,\n",
    "                                          only_train=only_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfa5d9-f64f-4acf-b532-b84ad6ac599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cos_sim_histograms(metadata_df, cosine_similarity_df, images_path, only_train=True):\n",
    "    if only_train:\n",
    "        train_mask = metadata_df['split'] == 'train'\n",
    "        metadata_df = metadata_df[train_mask].reset_index(drop=True)\n",
    "        cosine_similarity_df = cosine_similarity_df[train_mask].reset_index(drop=True)\n",
    "    concept_names = list(metadata_df.columns[1:-1])\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(8,4), sharex=True)\n",
    "    bins = np.linspace(0, 1, 20)\n",
    "    for i, concept in enumerate(concept_names):\n",
    "        ix, iy = int(i/4), i%4\n",
    "        sns.kdeplot(cosine_similarity_df[metadata_df[concept]==1][concept], \n",
    "                    label='In concept', ax=axs[ix,iy])\n",
    "        sns.kdeplot(cosine_similarity_df[metadata_df[concept]==0][concept], \n",
    "                    label='Out of concept', ax=axs[ix,iy])\n",
    "        axs[ix,iy].set_xlabel('')\n",
    "        axs[ix,iy].set_ylabel('')\n",
    "        axs[ix,iy].set_title(concept)\n",
    "    \n",
    "    handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "    lgd = fig.legend(handles, labels, bbox_to_anchor=(1.2, 0.9))\n",
    "    xl = fig.supxlabel('Cosine Similarity')\n",
    "    yl = fig.supylabel('Proportion of samples')\n",
    "    title = fig.suptitle('Cosine similarity in/out of concept')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    print('Saving image...', end=' ')\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    if only_train:\n",
    "        cos_sims_image_path = os.path.join(images_path, 'train_cosine_similarities.png')\n",
    "    else:\n",
    "        cos_sims_image_path = os.path.join(images_path, 'cosine_similarities.png')\n",
    "    fig.savefig(cos_sims_image_path, bbox_extra_artists=(lgd,xl,yl,title), \n",
    "                bbox_inches='tight')\n",
    "    print('Done.')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa13d31-70ad-4230-97f2-d9f43200fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cos_sim_histograms(metadata_df, cosine_similarity_df, images_path, only_train=only_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8af53-932b-4d5e-8759-591a70003892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similarity_concepts(concepts, images_path, only_train=True):\n",
    "    concept_embs = torch.stack(list(concepts.values()), dim=0)\n",
    "    concept_names = list(concepts.keys())\n",
    "    cos_sim_concepts_df = compute_cosine_sims(concept_embs, \n",
    "                                              metadata_df,\n",
    "                                              concept_embs, \n",
    "                                              concept_names, \n",
    "                                              '', save=False)\n",
    "    cos_sim_concepts_df['Concept'] = list(concepts.keys())\n",
    "    cos_sim_concepts_df = cos_sim_concepts_df.set_index('Concept')\n",
    "    ax = sns.heatmap(cos_sim_concepts_df, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "               cbar_kws={'label': 'Cosine similarity'})\n",
    "    ax.set_title('Cosine similarity between concepts')\n",
    "\n",
    "    print('Saving image...', end=' ')\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    if only_train:\n",
    "        cos_sims_image_path = os.path.join(images_path, 'train_cosine_similarities_concepts.png')\n",
    "    else:\n",
    "        cos_sims_image_path = os.path.join(images_path, 'cosine_similarities_concepts.png')\n",
    "    plt.savefig(cos_sims_image_path)\n",
    "    print('Done.')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbac3e-cd87-436e-ba07-007dc8a23c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similarity_concepts(concepts, images_path, only_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f67313-3c69-41ca-9929-8986148253cd",
   "metadata": {},
   "source": [
    "## Concept presence models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dc1ec-7137-47da-bbd5-14cab5b8da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(f'../Data/{dataset_name}/metadata.csv')\n",
    "embeddings = torch.load(f'Embeddings/{dataset_name}/embeddings.pt')\n",
    "cosine_similarity_df = pd.read_csv(f'Cosine_Similarities/{dataset_name}/cosine_similarities.csv')\n",
    "\n",
    "train_mask = metadata_df['split'] == 'train'\n",
    "train_embeddings = embeddings[train_mask]\n",
    "train_metadata_df = metadata_df[train_mask].reset_index(drop=True)\n",
    "train_cosine_similarity_df = cosine_similarity_df[train_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c20d9a-a4ac-4557-b6b9-16f70e8fe6b8",
   "metadata": {},
   "source": [
    "### (M1) Cosine similarity global threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9ee8a-9c89-45cd-aabd-4f050b0e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_global_threshold\n",
    "\n",
    "m1_models, m1_global_train_error, m1_train_errors = get_global_threshold(train_metadata_df, train_cosine_similarity_df)\n",
    "m1_train_errors['Model'] = 'GT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46f3a5-d027-441b-af91-7fe9a314eb8b",
   "metadata": {},
   "source": [
    "### (M2) Cosine similarity individual threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915d7fc-b6ee-4615-b510-47796d1ca3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_individual_thresholds\n",
    "\n",
    "m2_models, m2_train_errors = get_individual_thresholds(train_metadata_df, train_cosine_similarity_df)\n",
    "m2_train_errors['Model'] = 'CT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a99ff1-8e76-4e1a-b4fb-fe13fe11968b",
   "metadata": {},
   "source": [
    "### (M3) Global cosine similarity logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e4520-716b-4c12-85c5-e0343c374bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_global_similarity_log_reg\n",
    "\n",
    "m3_models, m3_global_train_error, m3_train_errors = get_global_similarity_log_reg(train_metadata_df, \n",
    "                                                                                  train_cosine_similarity_df)\n",
    "m3_train_errors['Model'] = 'GLR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b467f4-30f6-4ddb-81a2-c287a572bb71",
   "metadata": {},
   "source": [
    "### (M4) Cosine similarity logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbb43a-9628-4f4e-92e7-23af9ec2e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_similarity_log_reg\n",
    "\n",
    "m4_models, m4_train_errors = get_similarity_log_reg(train_metadata_df, train_cosine_similarity_df)\n",
    "m4_train_errors['Model'] = 'CLR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d9415-2b72-484b-be19-fc717c1e3279",
   "metadata": {},
   "source": [
    "### (M5) Embeddings logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fde41f-1d57-4597-9c4b-4621534118f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_embeddings_log_reg\n",
    "\n",
    "m5_models, m5_train_errors = get_embeddings_log_reg(train_embeddings, train_metadata_df, train_cosine_similarity_df)\n",
    "m5_train_errors['Model'] = 'EmbCLR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69ff3d-10e8-498e-a6ad-a5699f00db77",
   "metadata": {},
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d4c51-74ff-4e0e-bed6-47490aa3fc03",
   "metadata": {},
   "source": [
    "### Train classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7681031-c5af-4a48-a04e-b0a864f44dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_comparison_df = pd.DataFrame.from_dict([m1_train_errors, \n",
    "                                              m2_train_errors,\n",
    "                                              m3_train_errors,\n",
    "                                              m4_train_errors,\n",
    "                                              m5_train_errors\n",
    "                                             ])\n",
    "error_comparison_df = error_comparison_df.set_index('Model')\n",
    "error_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fc9dc-506b-4f24-805c-a795aac90393",
   "metadata": {},
   "source": [
    "### Test classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd447c-f53b-49c6-a469-0751b8183641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_all_models_classification_metric\n",
    "\n",
    "metadata_df = pd.read_csv(os.path.join(data_path, 'metadata.csv'))\n",
    "cosine_similarity_df = pd.read_csv(os.path.join(cos_sims_path, 'train_cosine_similarities.csv'))\n",
    "hidden_states = torch.load(os.path.join(embeddings_path, 'embeddings.pt'))\n",
    "\n",
    "test_mask = metadata_df['split'] == 'test'\n",
    "test_hidden_states = hidden_states[test_mask]\n",
    "test_metadata_df = metadata_df[test_mask].reset_index(drop=True)\n",
    "test_cosine_similarity_df = cosine_similarity_df[test_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7dfe99-2efd-4e5c-83e3-8612233bfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy')\n",
    "models = {'GT': m1_models,\n",
    "          'CT': m2_models,\n",
    "          'GLR': m3_models,\n",
    "          'CLR': m4_models,\n",
    "          'EmbCLR': m5_models\n",
    "         }\n",
    "acc_df = get_all_models_classification_metric(models, test_metadata_df, test_cosine_similarity_df,\n",
    "                                         test_hidden_states, metric='Acc')\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07207ab6-1618-487b-915c-a4a85332ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test F1')\n",
    "f1_df = get_all_models_classification_metric(models, test_metadata_df, test_cosine_similarity_df,\n",
    "                                         test_hidden_states, metric='F1')\n",
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0501c-e14d-4364-a077-7f190be95205",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test AUC')\n",
    "auc_df = get_all_models_classification_metric(models, test_metadata_df, test_cosine_similarity_df,\n",
    "                                         test_hidden_states, metric='AUC')\n",
    "auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62941a-3960-4d00-a1af-d7b8c18e5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test K1')\n",
    "k1_df = get_all_models_classification_metric(models, test_metadata_df, test_cosine_similarity_df,\n",
    "                                         test_hidden_states, metric='K1')\n",
    "k1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64fef6-db51-4280-84d8-6a1e1bcd90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test K2')\n",
    "k2_df = get_all_models_classification_metric(models, test_metadata_df, test_cosine_similarity_df,\n",
    "                                         test_hidden_states, metric='K2')\n",
    "k2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead9af1-0f48-4366-834e-cdd2a7cbb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Kmax')\n",
    "kmax_df = get_all_models_classification_metric(models, test_metadata_df, test_cosine_similarity_df,\n",
    "                                         test_hidden_states, metric='Kmax')\n",
    "kmax_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0cf2b-f22a-4d1f-a39e-1498e12c22f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}