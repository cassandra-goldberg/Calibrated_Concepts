{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3806345-3c6b-41bf-9f74-4b551b29c7d5",
   "metadata": {},
   "source": [
    "# Process True False Dataset\n",
    "\n",
    "Dataset from the paper [The Internal State of an LLM Knows When It's Lying](https://aclanthology.org/2023.findings-emnlp.68.pdf)\n",
    "\n",
    "You can download the dataset [here](http://azariaa.com/Content/Datasets/true-false-dataset.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f6c14-d2bf-4573-8048-a08df2634e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"CPU\"\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec63df3-9723-46a3-bada-4bf7e38e5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'true-false-dataset'\n",
    "categories = ['animals', 'cities', 'companies', 'elements', \n",
    "              'facts', 'generated', 'inventions']\n",
    "\n",
    "data_path = f'../Data/{dataset_name}'\n",
    "embeddings_path = f'Embeddings/{dataset_name}'\n",
    "concepts_path = f'Concepts/{dataset_name}'\n",
    "cos_sims_path = f'Cosine_Similarities/{dataset_name}'\n",
    "images_path = f'Images/{dataset_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240aa09-dc31-45f6-859e-f3e5b77d3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file = os.path.join(embeddings_path, 'embeddings.pt')\n",
    "    \n",
    "if os.path.exists(embeddings_file):\n",
    "    print('Embeddings file found. No need to load model and tokenizer.')\n",
    "    model = None\n",
    "    tokenizer = None\n",
    "else:\n",
    "    print('Embeddings file NOT found. Loading model and tokenizer...')\n",
    "    \n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()\n",
    "    \n",
    "    model_name_or_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a956e43-ba35-4ae6-b4a8-43b6472dd9d9",
   "metadata": {},
   "source": [
    "## Processing statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588f998-dc4b-4aba-9b00-4bc23ef91f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(category, data_path):\n",
    "    cat_path = os.path.join(data_path, f'{category}_true_false.csv')\n",
    "    df_cat = pd.read_csv(cat_path)\n",
    "    df_cat[category] = 1\n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520ed8c-f445-4df4-b4e4-95e69754fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(categories, data_path):\n",
    "    df_list = []\n",
    "    for category in categories:\n",
    "        df_cat = get_category(category, data_path=data_path)\n",
    "        df_list.append(df_cat)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    df = df.fillna(0)\n",
    "    for category in categories:\n",
    "        df[category] = df[category].astype(int)\n",
    "    df = df.rename(columns={'label': 'true'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1df244-4b20-422c-ab53-1aab03a2eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(statements, model, tokenizer, embeddings_path, \n",
    "                      device=device, save=True):\n",
    "    embeddings_file = os.path.join(embeddings_path, 'embeddings.pt')\n",
    "    \n",
    "    if os.path.exists(embeddings_file):\n",
    "        print('   Hidden states file found.')\n",
    "        hidden_states = torch.load(embeddings_file)\n",
    "    else:\n",
    "        print('   Hidden states file NOT found.')\n",
    "        hidden_states = []\n",
    "        for statement in tqdm(statements, desc='Getting hidden states'):\n",
    "            tokenized_prompt = tokenizer(statement, return_tensors=\"pt\").to(device)\n",
    "            output = model(**tokenized_prompt, output_hidden_states=True)\n",
    "            \n",
    "            features = output.hidden_states[-1][0][-1]\n",
    "            hidden_state = features.cpu().detach()\n",
    "            hidden_states.append(hidden_state)\n",
    "            \n",
    "            del output\n",
    "            del features\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        hidden_states = torch.stack(hidden_states, dim=0)\n",
    "        # Center embeddings\n",
    "        average_embedding = torch.mean(hidden_states, 0) \n",
    "        centered_hidden_states = hidden_states - average_embedding\n",
    "        if save:\n",
    "            os.makedirs(embeddings_path, exist_ok=True)\n",
    "            torch.save(hidden_states, embeddings_file)\n",
    "            \n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9b7fa-5c40-4131-9de7-c9e9a976f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(categories, model, tokenizer, data_path, embeddings_path):\n",
    "    print('Getting statements...', end=' ')\n",
    "    df = get_categories(categories, data_path=data_path)\n",
    "    df.to_csv(os.path.join(data_path, 'metadata.csv'), index=False)\n",
    "    statements = df['statement'].to_list()\n",
    "    print('Done.')\n",
    "\n",
    "    print('Getting hidden states...')\n",
    "    hidden_states = get_hidden_states(statements, model, tokenizer, embeddings_path)\n",
    "    print('Done.')\n",
    "\n",
    "    return df, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12de0a-0af1-4350-a057-2304b62c7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, hidden_states = process_data(categories, model, tokenizer, data_path, embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad90a36-3bfe-479e-951f-932726f3a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of statements: {df.shape[0]}')\n",
    "print(f'Number of true statements: {df[df[\"true\"] == 1].shape[0]}')\n",
    "print(f'Number of false statements: {df[df[\"true\"] == 0].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c039b2d-be13-4cf9-8b03-5674895f3771",
   "metadata": {},
   "source": [
    "## Computing concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb60d4c-9cf4-47c7-a157-aff00c43a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_concept(concept, df, hidden_states):\n",
    "    # Get embeddings from the concept\n",
    "    hidden_states_cat = hidden_states[df[concept]==1] \n",
    "    # Get average embedding\n",
    "    concept_vect = torch.mean(hidden_states_cat, 0) \n",
    "    # Normalize vector\n",
    "    concept_vect = concept_vect / concept_vect.norm() \n",
    "    return concept_vect\n",
    "\n",
    "def compute_concepts(df, hidden_states, concepts_path, save=True):\n",
    "    concept_names = list(df.columns[1:])\n",
    "    concepts = {}\n",
    "\n",
    "    print('Computing concept vectors...', end=' ')\n",
    "    for concept in concept_names:\n",
    "        concept_vect = compute_single_concept(concept, df, hidden_states)\n",
    "        concepts[concept] = concept_vect\n",
    "    print('Done.')\n",
    "        \n",
    "    if save:\n",
    "        print('Saving concepts...', end=' ')\n",
    "        os.makedirs(concepts_path, exist_ok=True)\n",
    "        concepts_path = os.path.join(concepts_path, 'concepts.pt')\n",
    "        torch.save(concepts, concepts_path)\n",
    "        print('Done.')\n",
    "\n",
    "    print(f'Concepts computed: {list(concepts.keys())}')\n",
    "    return concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fdb6f-1f86-4a3f-96c2-2b653c254645",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = compute_concepts(df, hidden_states, concepts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39210c-4073-44cf-bc7d-5b239cb1c640",
   "metadata": {},
   "source": [
    "## Compute cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6c2cb-860c-4ffd-a316-00049b43d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_sims(hidden_states, concept_embs, concept_names, cos_sims_path,\n",
    "                        save=True):\n",
    "    print('Computing cosine similarities...', end=' ')\n",
    "    similarities = cosine_similarity(hidden_states, concept_embs)\n",
    "    sim_df = pd.DataFrame(similarities, columns=concept_names)\n",
    "    print('Done.')\n",
    "    if save:\n",
    "        print('Saving cosine similarities...', end=' ')\n",
    "        os.makedirs(cos_sims_path, exist_ok=True)\n",
    "        cos_sims_df_path = os.path.join(cos_sims_path, 'cosine_similarities.csv')\n",
    "        sim_df.to_csv(cos_sims_df_path, index=False)\n",
    "        print('Done.')\n",
    "        \n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c89b6-10f0-42f6-b228-c2b3eb7b6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embs = torch.stack(list(concepts.values()), dim=0)\n",
    "concept_names = list(concepts.keys())\n",
    "sim_df = compute_cosine_sims(hidden_states, concept_embs, concept_names, cos_sims_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfa5d9-f64f-4acf-b532-b84ad6ac599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cos_sim_histograms(df, sim_df, images_path):\n",
    "    concept_names = list(df.columns[1:])\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(8,4), sharex=True)\n",
    "    bins = np.linspace(0, 1, 20)\n",
    "    for i, concept in enumerate(concept_names):\n",
    "        ix, iy = int(i/4), i%4\n",
    "        sns.kdeplot(sim_df[df[concept]==1][concept], \n",
    "                    label='In concept', ax=axs[ix,iy])\n",
    "        sns.kdeplot(sim_df[df[concept]==0][concept], \n",
    "                    label='Out of concept', ax=axs[ix,iy])\n",
    "        axs[ix,iy].set_xlabel('')\n",
    "        axs[ix,iy].set_ylabel('')\n",
    "        axs[ix,iy].set_title(concept)\n",
    "    \n",
    "    handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "    lgd = fig.legend(handles, labels, bbox_to_anchor=(1.2, 0.9))\n",
    "    xl = fig.supxlabel('Cosine Similarity')\n",
    "    yl = fig.supylabel('Proportion of samples')\n",
    "    title = fig.suptitle('Cosine similarity in/out of concept')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    print('Saving image...', end=' ')\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    cos_sims_image_path = os.path.join(images_path, 'cosine_similarities.png')\n",
    "    fig.savefig(cos_sims_image_path, bbox_extra_artists=(lgd,xl,yl,title), \n",
    "                bbox_inches='tight')\n",
    "    print('Done.')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa13d31-70ad-4230-97f2-d9f43200fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cos_sim_histograms(df, sim_df, images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8af53-932b-4d5e-8759-591a70003892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similarity_concepts(concepts, images_path):\n",
    "    concept_embs = torch.stack(list(concepts.values()), dim=0)\n",
    "    concept_names = list(concepts.keys())\n",
    "    cos_sim_concepts_df = compute_cosine_sims(concept_embs, \n",
    "                                              concept_embs, \n",
    "                                              concept_names, \n",
    "                                              '', save=False)\n",
    "    cos_sim_concepts_df['Concept'] = list(concepts.keys())\n",
    "    cos_sim_concepts_df = cos_sim_concepts_df.set_index('Concept')\n",
    "    ax = sns.heatmap(cos_sim_concepts_df, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "               cbar_kws={'label': 'Cosine similarity'})\n",
    "    ax.set_title('Cosine similarity between concepts')\n",
    "\n",
    "    print('Saving image...', end=' ')\n",
    "    os.makedirs(images_path, exist_ok=True)\n",
    "    cos_sims_image_path = os.path.join(images_path, 'cosine_similarities_concepts.png')\n",
    "    plt.savefig(cos_sims_image_path)\n",
    "    print('Done.')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbac3e-cd87-436e-ba07-007dc8a23c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similarity_concepts(concepts, images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f67313-3c69-41ca-9929-8986148253cd",
   "metadata": {},
   "source": [
    "## Threshold-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217c9c2-9cbf-4dc7-b078-634965ff3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_eval, thresh=None):\n",
    "        if thresh is None:\n",
    "            thresh = self.thresh\n",
    "        return (X_eval[:,0] > thresh).astype(int)\n",
    "\n",
    "    def loss(self, thresh):\n",
    "        y_pred = self.predict(self.X, thresh)\n",
    "        error = 1 - accuracy_score(self.y, y_pred)\n",
    "        return error\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        result = minimize_scalar(self.loss, bounds=(-1, 1), method='bounded')\n",
    "        self.thresh, self.loss = result.x, result.fun\n",
    "        return self.thresh, self.loss\n",
    "\n",
    "def train_test_threshold(X, y, stratify_list=None):\n",
    "    model = ThresholdModel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.33, \n",
    "                                                        random_state=42,\n",
    "                                                        stratify=stratify_list)\n",
    "    thresh, train_error = model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test, thresh)\n",
    "    test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "    return thresh, train_error, test_error\n",
    "\n",
    "def get_concept_X_y_list(df, sim_df, concept):\n",
    "    X = sim_df[[concept]].to_numpy()\n",
    "    y = (df[concept]==1).to_numpy().astype(int)\n",
    "    concept_list = df[concept]\n",
    "    return X, y, concept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7eb32-272d-4558-9a7f-31bfcaf289c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_threshold(df, sim_df, verbose=True):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    concept_lists = []\n",
    "    concepts = list(sim_df.columns)\n",
    "    for concept in concepts:\n",
    "        X, y, concept_list = get_concept_X_y_list(df, sim_df, concept)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        concept_lists.append(concept_list)\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list)\n",
    "    concept_list = np.concatenate(concept_lists)\n",
    "\n",
    "    thresh, train_error, test_error = train_test_threshold(X, y, stratify_list=concept_list)\n",
    "    if verbose:\n",
    "        print(f'Global threshold: {thresh:.3f}')\n",
    "        print(f'Train error: {train_error:.3f} | Test error: {test_error:.3f}')\n",
    "    return thresh, train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9ee8a-9c89-45cd-aabd-4f050b0e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_thresh, global_train_error, global_test_error = get_global_threshold(df, sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7abacb-d3cf-4810-8ecb-64f5dc0f85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_threshold(df, sim_df, concept):\n",
    "    X, y, concept_list = get_concept_X_y_list(df, sim_df, concept)\n",
    "    thresh, train_error, test_error = train_test_threshold(X, y, stratify_list=concept_list)\n",
    "    return thresh, train_error, test_error\n",
    "\n",
    "def get_individual_thresholds(df, sim_df, verbose=True):\n",
    "    concepts = list(sim_df.columns)\n",
    "    thresholds = {}\n",
    "    train_errors = {}\n",
    "    test_errors = {}\n",
    "    for concept in concepts:\n",
    "        thresh, train_error, test_error = get_concept_threshold(df, sim_df, concept)\n",
    "        thresholds[concept] = thresh\n",
    "        train_errors[concept] = train_error\n",
    "        test_errors[concept] = test_error\n",
    "        if verbose:\n",
    "            print(f'Concept: {concept.ljust(10)} | Threshold: {thresh:.3f} | Train error: {train_error:.3f} | Test error: {test_error:.3f}')\n",
    "    return thresholds, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915d7fc-b6ee-4615-b510-47796d1ca3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds, train_errors, test_errors = get_individual_thresholds(df, sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a271576-89a1-40f9-9b35-a761f4f4e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_concept_thresh_errors(test_errors):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.barplot(test_errors, orient=\"y\", ax=ax)\n",
    "    ax.set_xlabel('Classification error')\n",
    "    ax.set_ylabel('Concept')\n",
    "    ax.set_title('Classification error of concept-specific threshold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6291cb-1fac-4fee-957b-fa5b10d8879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_concept_thresh_errors(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439c5a2-feca-4ca9-9cfe-a6e64ef4e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
