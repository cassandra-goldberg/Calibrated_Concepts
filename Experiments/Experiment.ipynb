{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c585a1-8b88-4de8-9b51-959de57f0cc7",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7250844-ddfb-4bac-a26e-ae825060c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import get_global_threshold, get_individual_thresholds\n",
    "from models import get_global_similarity_log_reg, get_similarity_log_reg\n",
    "from models import get_embeddings_log_reg\n",
    "from models import get_global_sim_X_y, get_concept_sim_X_y\n",
    "\n",
    "from calibration_framework import apply_platt_scaling, apply_isotonic_regression, apply_temperature_scaling\n",
    "from calibration_framework import apply_histogram_binning, apply_beta_calibration\n",
    "\n",
    "from utils import compare_all_models_calibration_metric, compare_all_models_calibration_avg, compare_all_models_calibration_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f5fa5-d70e-4af3-af96-1d30893c0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'CLEVR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea5459-199e-4c30-b4b9-cea8e90c700a",
   "metadata": {},
   "source": [
    "## 1. Get pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4803d97-4aa0-4880-b255-4387b5b0866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(f'../Data/{dataset_name}/metadata.csv')\n",
    "embeddings = torch.load(f'Embeddings/{dataset_name}/embeddings.pt')\n",
    "cosine_similarity_df = pd.read_csv(f'Cosine_Similarities/{dataset_name}/train_cosine_similarities.csv')\n",
    "\n",
    "if dataset_name == 'CLEVR':\n",
    "    metadata_df = metadata_df.drop(['size::large','material::rubber'], axis=1)\n",
    "    cosine_similarity_df = cosine_similarity_df.drop(['size::large','material::rubber'], axis=1)\n",
    "\n",
    "concepts = list(cosine_similarity_df.columns)\n",
    "\n",
    "train_mask = metadata_df['split'] == 'train'\n",
    "train_embeddings = embeddings[train_mask]\n",
    "train_metadata_df = metadata_df[train_mask].reset_index(drop=True)\n",
    "train_cosine_similarity_df = cosine_similarity_df[train_mask].reset_index(drop=True)\n",
    "\n",
    "cal_mask = metadata_df['split'] == 'calibration'\n",
    "cal_embeddings = embeddings[cal_mask]\n",
    "cal_metadata_df = metadata_df[cal_mask].reset_index(drop=True)\n",
    "cal_cosine_similarity_df = cosine_similarity_df[cal_mask].reset_index(drop=True)\n",
    "\n",
    "test_mask = metadata_df['split'] == 'test'\n",
    "test_embeddings = embeddings[test_mask]\n",
    "test_metadata_df = metadata_df[test_mask].reset_index(drop=True)\n",
    "test_cosine_similarity_df = cosine_similarity_df[test_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8397156-bca7-4f14-ae79-f7578c11da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dce939-1cb8-44d6-b131-80b4df30622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aea660-cd20-4bcf-a2cf-d6d3f42cbeaa",
   "metadata": {},
   "source": [
    "## 2. Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7af94-67be-4edc-a07d-6f5b1673f90c",
   "metadata": {},
   "source": [
    "### (GT) Global Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2abf9-1a4e-4ae6-8680-97e79229ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_models, m1_global_train_error, m1_train_errors = get_global_threshold(train_metadata_df, train_cosine_similarity_df,\n",
    "                                                                        verbose=False)\n",
    "m1_train_errors['Model'] = 'GT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d85b7c-d52b-4ea8-971c-e3b5fe2c9516",
   "metadata": {},
   "source": [
    "### (CT) Concept Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54784061-e30a-4d03-933d-74a594984731",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_models, m2_train_errors = get_individual_thresholds(train_metadata_df, train_cosine_similarity_df, verbose=False)\n",
    "m2_train_errors['Model'] = 'CT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf243a-a3bb-41a4-ae9f-8f5673c1cef2",
   "metadata": {},
   "source": [
    "### (GLR) Global Similarity LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5609fa-5979-4b56-9343-f9d4d23c3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_models, m3_global_train_error, m3_train_errors = get_global_similarity_log_reg(train_metadata_df, \n",
    "                                                                                  train_cosine_similarity_df,\n",
    "                                                                                  verbose=False)\n",
    "m3_train_errors['Model'] = 'GLR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a482589-40c4-414a-949a-ee0cb317ecd4",
   "metadata": {},
   "source": [
    "### (CLR) Concept Similarity LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9285f41-1e64-40aa-bdb2-bedb12f207e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_models, m4_train_errors = get_similarity_log_reg(train_metadata_df, train_cosine_similarity_df, verbose=False)\n",
    "m4_train_errors['Model'] = 'CLR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62295d2c-a839-44b9-b122-1a71737035c2",
   "metadata": {},
   "source": [
    "### (EmbCLR) Embeddings Concept LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d69dfc-e33a-4145-b573-54a38dce308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_models, m5_train_errors = get_embeddings_log_reg(train_embeddings, train_metadata_df, train_cosine_similarity_df,\n",
    "                                                   verbose=False)\n",
    "m5_train_errors['Model'] = 'EmbCLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b535e-a78f-4ef2-89f5-65239ceb8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = {'GT': m1_models,\n",
    "               'CT': m2_models,\n",
    "               'GLR': m3_models,\n",
    "               'CLR': m4_models,\n",
    "               'EmbCLR': m5_models\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ac801-5aff-44bb-ab5e-aa0a9d9e0aaa",
   "metadata": {},
   "source": [
    "### 2.1 Evaluate training classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25214a4f-3742-4351-8081-27426f127ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_comparison_df = pd.DataFrame.from_dict([m1_train_errors, \n",
    "                                              m2_train_errors,\n",
    "                                              m3_train_errors,\n",
    "                                              m4_train_errors,\n",
    "                                              m5_train_errors\n",
    "                                             ])\n",
    "error_comparison_df = error_comparison_df.set_index('Model')\n",
    "if dataset_name == 'CUB':\n",
    "    error_comparison_df = error_comparison_df.transpose()\n",
    "    display(error_comparison_df.describe())\n",
    "else:\n",
    "    display(error_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c8856-ea2e-442b-9b5b-1af611643fde",
   "metadata": {},
   "source": [
    "## 3. Calibrate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149407f-b0bb-4573-8c2b-7a1c7780f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cal, y_cal, _, _ = get_global_sim_X_y(cal_metadata_df, cal_cosine_similarity_df)\n",
    "\n",
    "m3_models_cal = {}\n",
    "\n",
    "m3_models_cal['Platt'] = apply_platt_scaling(m3_models, X_cal, y_cal)\n",
    "m3_models_cal['Isotonic'] = apply_isotonic_regression(m3_models, X_cal, y_cal)\n",
    "m3_models_cal['Temperature'] = apply_temperature_scaling(m3_models, X_cal, y_cal, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61be113",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_models_cal['Histogram'] = apply_histogram_binning(m3_models, X_cal, y_cal, nbins=10)\n",
    "m3_models_cal['Beta'] = apply_beta_calibration(m3_models, X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2bccf-ebf4-4e40-8f47-311d44a6918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_models_cal = {}\n",
    "m4_models_cal['Platt'] = {}\n",
    "m4_models_cal['Isotonic'] = {}\n",
    "m4_models_cal['Temperature'] = {}\n",
    "\n",
    "m4_models_cal['Histogram'] = {}\n",
    "m4_models_cal['Beta'] = {}\n",
    "\n",
    "for concept in m4_models.keys():\n",
    "    X_cal, y_cal = get_concept_sim_X_y(cal_metadata_df, cal_cosine_similarity_df, concept)\n",
    "\n",
    "    m4_models_cal['Platt'][concept] = apply_platt_scaling(m4_models[concept], X_cal, y_cal)\n",
    "    m4_models_cal['Isotonic'][concept] = apply_isotonic_regression(m4_models[concept], X_cal, y_cal)\n",
    "    m4_models_cal['Temperature'][concept] = apply_temperature_scaling(m4_models[concept], X_cal, y_cal, verbose=False)\n",
    "    \n",
    "    m4_models_cal['Histogram'][concept] = apply_histogram_binning(m4_models[concept], X_cal, y_cal, nbins=10)\n",
    "    m4_models_cal['Beta'][concept] = apply_beta_calibration(m4_models[concept], X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e77499-ed5c-4931-bd0b-1a146d7ed135",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_models_cal = {}\n",
    "m5_models_cal['Platt'] = {}\n",
    "m5_models_cal['Isotonic'] = {}\n",
    "m5_models_cal['Temperature'] = {}\n",
    "\n",
    "m5_models_cal['Histogram'] = {}\n",
    "m5_models_cal['Beta'] = {}\n",
    "\n",
    "for concept in m5_models.keys():\n",
    "    X_cal = cal_embeddings\n",
    "    y_cal = (cal_metadata_df[concept]==1).to_numpy().astype(int)\n",
    "\n",
    "    m5_models_cal['Platt'][concept] = apply_platt_scaling(m5_models[concept], X_cal, y_cal)\n",
    "    m5_models_cal['Isotonic'][concept] = apply_isotonic_regression(m5_models[concept], X_cal, y_cal)\n",
    "    m5_models_cal['Temperature'][concept] = apply_temperature_scaling(m5_models[concept], X_cal, y_cal, verbose=False)\n",
    "    \n",
    "    m5_models_cal['Histogram'][concept] = apply_histogram_binning(m5_models[concept], X_cal, y_cal, nbins=10)\n",
    "    m5_models_cal['Beta'][concept] = apply_beta_calibration(m5_models[concept], X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f18ed-5218-44f0-a6ee-ee0af9135f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_models = {'GLR': m3_models_cal,\n",
    "                     'CLR': m4_models_cal,\n",
    "                     'EmbCLR': m5_models_cal\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20873e1-49dd-4041-9a3e-5c85dbc5035b",
   "metadata": {},
   "source": [
    "## 4. Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7518f5-1988-4a55-9c55-c02869a7a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = f\"Results/{dataset_name}/\"\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08301c-50aa-4dde-8163-061445fb6a74",
   "metadata": {},
   "source": [
    "### 4.1 Get a single metric for all models, calibration methods, and concepts\n",
    "\n",
    "**Use only if you don't have many concepts!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7399b-52d0-4ee5-9d14-e83b5487cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'K1'\n",
    "\n",
    "if len(concepts) <= 10:\n",
    "    metric_df = compare_all_models_calibration_metric(base_models, m3_models_cal, m4_models_cal, m5_models_cal,\n",
    "                                       test_metadata_df, test_cosine_similarity_df, test_embeddings, \n",
    "                                       metric=metric)\n",
    "    if not 'K' in metric:\n",
    "        display(metric_df.style.highlight_max(color='grey'))\n",
    "    else:\n",
    "        display(metric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c86e58-77e3-4ae5-8146-21dcb2a16149",
   "metadata": {},
   "source": [
    "### 4.2 Get the average of all metrics over the concepts for all models and calibration methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6f39d-7266-4130-bcce-9e86c28ae8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_avg_df = compare_all_models_calibration_avg(base_models, m3_models_cal, m4_models_cal, m5_models_cal,\n",
    "                                   test_metadata_df, test_cosine_similarity_df, test_embeddings)\n",
    "metrics_avg_df.to_csv(os.path.join(results_path, 'metrics_average.csv'))\n",
    "with open(os.path.join(results_path, 'metrics_average.tex'), 'w') as tf:\n",
    "     tf.write(metrics_avg_df.to_latex())\n",
    "\n",
    "with open(os.path.join(results_path, 'metrics_average_short.tex'), 'w') as tf:\n",
    "     tf.write(metrics_avg_df[['Acc','K1','Kmax']].to_latex())\n",
    "    \n",
    "metrics_avg_df#.style.highlight_max(color='grey', subset=['Acc','F1','AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419670fb-ca51-42e8-8adb-4c6239b3c805",
   "metadata": {},
   "source": [
    "### 4.3 Get all metrics for all models and calibration methods for a single concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76300726-0f9c-463d-9944-ef5e50d896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = concepts[0]\n",
    "\n",
    "metrics_concept_df = compare_all_models_calibration_concept(base_models, m3_models_cal, m4_models_cal, m5_models_cal,\n",
    "                                   test_metadata_df, test_cosine_similarity_df, test_embeddings,\n",
    "                                      concept=concept)\n",
    "metrics_concept_df.to_csv(os.path.join(results_path, f'metrics_concept_{concept}.csv'))\n",
    "with open(os.path.join(results_path, f'metrics_concept_{concept}.tex'), 'w') as tf:\n",
    "     tf.write(metrics_concept_df.to_latex())\n",
    "    \n",
    "metrics_concept_df.style.highlight_max(color='grey', subset=['Acc','F1','AUC'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8446b84-9314-483b-a762-93550eb00494",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(concepts) < 10:\n",
    "    for concept in concepts:\n",
    "        metrics_concept_df = compare_all_models_calibration_concept(base_models, m3_models_cal, m4_models_cal, m5_models_cal,\n",
    "                                           test_metadata_df, test_cosine_similarity_df, test_embeddings,\n",
    "                                              concept=concept)\n",
    "        metrics_concept_df.to_csv(os.path.join(results_path, f'metrics_concept_{concept}.csv'))\n",
    "        with open(os.path.join(results_path, f'metrics_concept_{concept}.tex'), 'w') as tf:\n",
    "             tf.write(metrics_concept_df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f545d-6ae8-4004-9210-b902059d3ba3",
   "metadata": {},
   "source": [
    "## 5. Calibration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527da33-e3e5-4c73-973b-1a7de7a9d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import plot_calibration_curves_concept, plot_calibration_curves_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff04b88-3d81-425c-9cfe-1906c094d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_calibration_curves_avg(test_metadata_df, test_cosine_similarity_df, \n",
    "                                test_embeddings, base_models, calibrated_models,\n",
    "                                  results_path, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26386f98-c250-4abb-a19d-ba93c6a263c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(concepts) < 10:\n",
    "    for concept in concepts:\n",
    "        fig = plot_calibration_curves_concept(test_metadata_df, test_cosine_similarity_df, \n",
    "                                            test_embeddings, base_models, calibrated_models,\n",
    "                                            concept, results_path)\n",
    "        fig.show()\n",
    "else:\n",
    "    for concept in concepts[:10]:\n",
    "        fig = plot_calibration_curves_concept(test_metadata_df, test_cosine_similarity_df, \n",
    "                                            test_embeddings, base_models, calibrated_models,\n",
    "                                            concept, results_path)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203c440-b018-4615-8f0b-7315ab59ffaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af48bc-6ad3-4dd1-b371-f3b4453fd1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b793470c",
   "metadata": {},
   "source": [
    "## Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e686937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "n = 501 # discretization\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# None\n",
    "plt.plot([0, 1], [0, 1], label = 'None', color = 'grey', linestyle = 'dashed', alpha = 0.5)\n",
    "\n",
    "# Histogram binning\n",
    "x_vals = m3_models_cal['Histogram'].calibrator.get_params()['_bin_bounds'][0]\n",
    "y_vals = m3_models_cal['Histogram'].calibrator.get_params()['_bin_map']\n",
    "y_vals = np.append(y_vals, y_vals[-1])\n",
    "nbins = m3_models_cal['Histogram'].calibrator.get_params()['bins']\n",
    "plt.step(x_vals, y_vals, where = 'post', label = 'Histogram ({} bins)'.format(nbins), color = colors[0])\n",
    "\n",
    "# Isotonic regression (would be nice if I could find the true bins but this will do)\n",
    "x_vals = np.linspace(0, 1, num=n, endpoint=True)[1:-1]\n",
    "y_vals = m3_models_cal['Isotonic'].calibrated_classifiers_[0].calibrators[0].predict(logit(x_vals))\n",
    "plt.plot(x_vals, y_vals, label = 'Isotonic', color = colors[1])\n",
    "\n",
    "# Platt scaling\n",
    "x_vals = np.linspace(0, 1, num=n, endpoint=True)[1:-1]\n",
    "y_vals = m3_models_cal['Platt'].calibrated_classifiers_[0].calibrators[0].predict(logit(x_vals))\n",
    "tmp = m3_models_cal['Platt'].calibrated_classifiers_[0].calibrators[0]\n",
    "a, b = tmp.a_, tmp.b_\n",
    "plt.plot(x_vals, y_vals, label = 'Platt (A={:.2f}, B={:.2f})'.format(a, b), color = colors[2])\n",
    "\n",
    "# Temperature scaling\n",
    "\n",
    "# Emma thinks this should be the correct version (it looks way more believable)\n",
    "x_vals = np.linspace(0, 1, num=n, endpoint=True)[1:-1]\n",
    "y_vals = expit(logit(x_vals) / m3_models_cal['Temperature'].temperature)\n",
    "T = m3_models_cal['Temperature'].temperature\n",
    "plt.plot(x_vals, y_vals, label = 'Temperature w/ logit (T={:.2f})'.format(T), color = colors[5])\n",
    "\n",
    "# This matches what the code currently does on data (softmax and no logit)\n",
    "tmp = m3_models_cal['Temperature']\n",
    "T = tmp.temperature\n",
    "x_vals_vec = np.array([1 - x_vals, x_vals]).T\n",
    "y_vals = tmp.softmax(x_vals_vec / tmp.temperature)[:, 1]\n",
    "plt.plot(x_vals, y_vals, label = 'Temperature (T={:.2f})'.format(T), color = colors[3])\n",
    "\n",
    "# Beta calibration\n",
    "x_vals = np.linspace(0, 1, num=n, endpoint=True)\n",
    "y_vals = m3_models_cal['Beta'].calibrator.transform(x_vals)\n",
    "tmp = m3_models_cal['Beta'].calibrator.get_params()\n",
    "a, b = tmp['_sites']['weights']['values']\n",
    "c = tmp['_sites']['bias']['values'][0]\n",
    "plt.plot(x_vals, y_vals, label = 'Beta (a={:.2f}, b={:.2f}, c={:.2f})'.format(a, b, c), color = colors[4])\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel('Base model probability estimate')\n",
    "ax.set_ylabel('Calibrated model probability estimate')\n",
    "ax.set_title('Calibrators of {} Model'.format('(M3) Global Similarity LogReg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a824482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_vals = m3_models.predict_proba(X_cal)\n",
    "# y_vals = m3_models_cal['Platt'].predict_proba(X_cal)\n",
    "# plt.scatter(x_vals, y_vals, label = 'Platt from data', s = 6, color = 'purple')\n",
    "\n",
    "# x_vals = m3_models.predict_proba(X_cal)\n",
    "# y_vals = m3_models_cal['Isotonic'].predict_proba(X_cal)\n",
    "# plt.scatter(x_vals, y_vals, label = 'Isotonic from data', s = 6, color = 'red')\n",
    "\n",
    "# x_vals = m3_models.predict_proba(X_cal)\n",
    "# y_vals = m3_models_cal['Temperature'].predict_proba(X_cal)\n",
    "# plt.scatter(x_vals, y_vals, label = 'Temperature from data', s = 6, color = 'violet')\n",
    "\n",
    "# x_vals = m3_models.predict_proba(X_cal)\n",
    "# y_vals = m3_models_cal['Beta'].predict_proba(X_cal)\n",
    "# plt.scatter(x_vals, y_vals, label = 'Beta from data', s = 6, color = 'violet') \n",
    "# why are a bunch of these giving me double vision, maybe they're giving probabilities for both true and false labels?\n",
    "\n",
    "# tmp = m3_models_cal['Beta'].calibrator.get_params()\n",
    "# a, b = tmp['_sites']['weights']['values']\n",
    "# c = tmp['_sites']['bias']['values'][0]\n",
    "# y_vals = np.exp(c) * x_vals**a / (1 - x_vals)**b\n",
    "# y_vals = 1 / (1 + (1/y_vals))\n",
    "# plt.plot(x_vals, y_vals, label = 'Beta guess')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}